FROM quay.io/pypa/manylinux2014_x86_64
LABEL maintainer "Joakim AndÃ©n"

ENV CUDA_MAJOR 12
ENV CUDA_MINOR 0

ENV CUDART_MICRO 146
ENV LIBRARIES_MICRO 1
ENV NVTX_MICRO 140
ENV NVML_MICRO 140
ENV COMMAND_LINE_TOOLS_MICRO 1
ENV MINIMAL_BUILD_MICRO 1
ENV CUBLAS_MICRO 2.224

ENV CUDA_DASH_VERSION ${CUDA_MAJOR}-${CUDA_MINOR}
ENV CUDA_DOT_VERSION ${CUDA_MAJOR}.${CUDA_MINOR}

ENV CUDA_VERSION_PREFIX ${CUDA_DASH_VERSION}-${CUDA_DOT_VERSION}

# ---- The following block adds layers for CUDA --- #
# base
RUN NVIDIA_GPGKEY_SUM=d0664fbbdb8c32356d45de36c5984617217b2d0bef41b93ccecd326ba3b80c87 && \
    curl -fsSL https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/D42D0685.pub | sed '/^Version/d' > /etc/pki/rpm-gpg/RPM-GPG-KEY-NVIDIA && \
    echo "$NVIDIA_GPGKEY_SUM  /etc/pki/rpm-gpg/RPM-GPG-KEY-NVIDIA" | sha256sum -c --strict -

COPY tools/cufinufft/docker/cuda${CUDA_DOT_VERSION}/cuda.repo /etc/yum.repos.d/cuda.repo

# For libraries in the cuda-compat-* package: https://docs.nvidia.com/cuda/eula/index.html#attachment-a
RUN yum install -y \
        cuda-cudart-${CUDA_VERSION_PREFIX}.${CUDART_MICRO}-1 \
        cuda-compat-${CUDA_DASH_VERSION} && \
    ln -s cuda-${CUDA_DOT_VERSION} /usr/local/cuda && \
    rm -rf /var/cache/yum/*

# nvidia-docker 1.0
RUN echo "/usr/local/nvidia/lib" >> /etc/ld.so.conf.d/nvidia.conf && \
    echo "/usr/local/nvidia/lib64" >> /etc/ld.so.conf.d/nvidia.conf

ENV PATH /usr/local/nvidia/bin:/usr/local/cuda/bin:${PATH}
ENV LD_LIBRARY_PATH ${LD_LIBRARY_PATH}:/usr/local/nvidia/lib:/usr/local/nvidia/lib64

# nvidia-container-runtime
ENV NVIDIA_VISIBLE_DEVICES all
ENV NVIDIA_DRIVER_CAPABILITIES compute,utility
ENV NVIDIA_REQUIRE_CUDA "cuda>=${CUDA_DOT_VERSION} brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441"

# runtime
RUN yum install -y \
        cuda-libraries-${CUDA_VERSION_PREFIX}.${LIBRARIES_MICRO}-1 \
        cuda-nvtx-${CUDA_VERSION_PREFIX}.${NVTX_MICRO}-1 && \
    rm -rf /var/cache/yum/*

# devel
RUN yum install -y \
        cuda-nvml-devel-${CUDA_VERSION_PREFIX}.${NVML_MICRO}-1 \
        cuda-command-line-tools-${CUDA_VERSION_PREFIX}.${COMMAND_LINE_TOOLS_MICRO}-1 \
        cuda-cudart-devel-${CUDA_VERSION_PREFIX}.${CUDART_MICRO}-1 \
        cuda-libraries-devel-${CUDA_VERSION_PREFIX}.${LIBRARIES_MICRO}-1 \
        cuda-minimal-build-${CUDA_VERSION_PREFIX}.${MINIMAL_BUILD_MICRO}-1 \
        libcublas-devel-${CUDA_VERSION_PREFIX}.${CUBLAS_MICRO}-1 && \
    rm -rf /var/cache/yum/*

ENV LIBRARY_PATH /usr/local/cuda/lib64/stubs

# /CUDA #

# finufft reqs
RUN yum install -y \
        cmake \
        fftw-devel && \
    rm -rf /var/cache/yum/*

# Okay, so now we can begin cufinufft

# We need to build the CUDA code now.
# assume we are building container in the root of the git repo...
COPY . /io
RUN mkdir -p /io/build
WORKDIR /io/build
RUN cmake -D FINUFFT_USE_CUDA=ON -D FINUFFT_USE_CPU=OFF -D CMAKE_CUDA_ARCHITECTURES="50;60;70;75;80" -DBUILD_TESTING=ON -DFINUFFT_BUILD_TESTS=ON ..
RUN make -j4

# And we need to pack it in our LD path
ENV LD_LIBRARY_PATH /io/build:${LD_LIBRARY_PATH}

CMD ["/bin/bash"]
